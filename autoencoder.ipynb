{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "autoencoder.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JiaSunDeepLearning/AutoEncoder/blob/master/autoencoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8x8aBr5b-KOm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FS7B0VjADGVw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62
        },
        "outputId": "51ab1b4d-bf8d-4c5a-88a3-aa1b11fb8302"
      },
      "source": [
        "with open('/content/drive/My Drive/Autoencodercheckpoint/foo.txt', 'w') as f:\n",
        "  f.write('Hello Google Drive!')\n",
        "!cat /content/drive/My\\ Drive/Autoencodercheckpoint/foo.txt"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hello Google Drive!"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TS5OLYoW-Z1W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "713ec4d1-edca-45b5-a6d0-9f5339b346d8"
      },
      "source": [
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3kSE2vG-dqW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "4a2beeea-78de-4d48-fb05-cfbda1a9e7d0"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "print(tf.__version__)\n",
        "import os\n",
        "import time\n",
        "import glob\n",
        "import imageio\n",
        "from IPython import display\n",
        "import pathlib\n",
        "import random\n",
        "import logging\n",
        "logger = tf.get_logger()\n",
        "logger.setLevel(logging.ERROR)\n",
        "import PIL\n",
        "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
        "zip_dir = tf.keras.utils.get_file('cats_and_dogs_filterted.zip', origin=_URL, extract=True)\n",
        "\n",
        "zip_dir_base = os.path.dirname(zip_dir)\n",
        "!find $zip_dir_base -type d -print\n",
        "print(zip_dir_base)\n",
        "\n",
        "base_dir = os.path.join(os.path.dirname(zip_dir), 'cats_and_dogs_filtered')\n",
        "path = os.path.join(base_dir, 'train/')\n",
        "print(path)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0-beta1\n",
            "Downloading data from https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
            "68608000/68606236 [==============================] - 1s 0us/step\n",
            "/root/.keras/datasets\n",
            "/root/.keras/datasets/cats_and_dogs_filtered\n",
            "/root/.keras/datasets/cats_and_dogs_filtered/train\n",
            "/root/.keras/datasets/cats_and_dogs_filtered/train/cats\n",
            "/root/.keras/datasets/cats_and_dogs_filtered/train/dogs\n",
            "/root/.keras/datasets/cats_and_dogs_filtered/validation\n",
            "/root/.keras/datasets/cats_and_dogs_filtered/validation/cats\n",
            "/root/.keras/datasets/cats_and_dogs_filtered/validation/dogs\n",
            "/root/.keras/datasets\n",
            "/root/.keras/datasets/cats_and_dogs_filtered/train/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwqIzxgK-pyS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "0f20820c-d6fe-49e0-d842-9921bf6d3c94"
      },
      "source": [
        "BATCH_SIZE = 50\n",
        "\n",
        "\n",
        "class CVAE(tf.keras.Model):\n",
        "    def __init__(self, latent_dim):\n",
        "        super(CVAE, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.inference_net = tf.keras.Sequential(\n",
        "            [\n",
        "                tf.keras.layers.Conv2D(\n",
        "                    filters=64, kernel_size=(5, 5), strides=(2, 2), activation='relu', data_format='channels_last',\n",
        "                    padding='valid'),\n",
        "                tf.keras.layers.BatchNormalization(),\n",
        "                tf.keras.layers.Conv2D(\n",
        "                    filters=128, kernel_size=(5, 5), strides=(2, 2), activation='relu', padding='valid'),\n",
        "                tf.keras.layers.BatchNormalization(),\n",
        "                tf.keras.layers.Conv2D(\n",
        "                    filters=256, kernel_size=(5, 5), strides=(2, 2), activation='relu', padding='valid'),\n",
        "                tf.keras.layers.BatchNormalization(),\n",
        "                tf.keras.layers.Conv2D(\n",
        "                    filters=512, kernel_size=(5, 5), strides=(2, 2), activation='relu', padding='valid'),\n",
        "                tf.keras.layers.BatchNormalization(),\n",
        "                tf.keras.layers.Flatten(),\n",
        "                # No activation\n",
        "                tf.keras.layers.Dropout(rate=0.3),\n",
        "                tf.keras.layers.Dense(1024, activation='relu'),\n",
        "\n",
        "                tf.keras.layers.Flatten(),\n",
        "                # No activation\n",
        "                tf.keras.layers.Dropout(rate=0.3),\n",
        "                tf.keras.layers.Dense(2048, activation='relu'),\n",
        "\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        self.generative_net = tf.keras.Sequential(\n",
        "            [\n",
        "                tf.keras.layers.InputLayer(input_shape=(2048,)),\n",
        "                tf.keras.layers.Dropout(rate=0.3),\n",
        "                tf.keras.layers.Dense(units=16 * 16 * 512, activation=tf.nn.relu),\n",
        "                tf.keras.layers.Reshape(target_shape=(16, 16, 512)),\n",
        "                tf.keras.layers.Conv2DTranspose(\n",
        "                    filters=256,\n",
        "                    kernel_size=(5, 5),\n",
        "                    strides=(2, 2),\n",
        "                    padding=\"SAME\",\n",
        "                    activation='relu'),\n",
        "                tf.keras.layers.BatchNormalization(),\n",
        "                tf.keras.layers.Conv2DTranspose(\n",
        "                    filters=128,\n",
        "                    kernel_size=(5, 5),\n",
        "                    strides=(2, 2),\n",
        "                    padding=\"SAME\",\n",
        "                    activation='relu'),\n",
        "                tf.keras.layers.BatchNormalization(),\n",
        "                tf.keras.layers.Conv2DTranspose(\n",
        "                    filters=32,\n",
        "                    kernel_size=(5, 5),\n",
        "                    strides=(2, 2),\n",
        "                    padding=\"SAME\",\n",
        "                    activation='relu'),\n",
        "                tf.keras.layers.BatchNormalization(),\n",
        "                # No activation\n",
        "                tf.keras.layers.Conv2DTranspose(\n",
        "                    filters=3, kernel_size=(5, 5), strides=(1, 1), padding=\"SAME\", activation='relu'),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    @tf.function\n",
        "    def sample(self, eps=None):\n",
        "        if eps is None:\n",
        "            eps = tf.random.normal(shape=(100, self.latent_dim))\n",
        "        return self.decode(eps, apply_sigmoid=True)\n",
        "\n",
        "    def encode(self, x):\n",
        "        # mean, logvar = tf.split(self.inference_net(x), num_or_size_splits=2, axis=1)\n",
        "        y = self.inference_net(x)\n",
        "        return y\n",
        "\n",
        "    def reparameterize(self, mean, logvar):\n",
        "        eps = tf.random.normal(shape=mean.shape)\n",
        "        return eps * tf.exp(logvar * .5) + mean\n",
        "\n",
        "    def decode(self, z, apply_sigmoid=False):\n",
        "        logits = self.generative_net(z)\n",
        "        if apply_sigmoid:\n",
        "            probs = tf.sigmoid(logits)\n",
        "            return probs\n",
        "\n",
        "        return logits\n",
        "\n",
        "    def sample_forward(self, x):\n",
        "        y = self.inference_net(x)\n",
        "        return y\n",
        "\n",
        "\n",
        "def log_normal_pdf(sample, mean, logvar, raxis=1):\n",
        "    log2pi = tf.math.log(2. * np.pi)\n",
        "    return tf.reduce_sum(\n",
        "        -.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi),\n",
        "        axis=raxis)\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def compute_loss(model, x):\n",
        "    z = model.encode(x)\n",
        "    # z = model.reparameterize(mean, logvar)\n",
        "    x_logit = model.decode(z)\n",
        "    mse = tf.keras.losses.MeanSquaredError()\n",
        "\n",
        "    # cross_ent = tf.nn.l2_loss(x_logit-x)\n",
        "    # cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=x)\n",
        "    # logpx_z = -tf.reduce_sum(cross_ent, axis=[1, 2, 3])\n",
        "    # logpx_z = -tf.reduce_sum(cross_ent)\n",
        "    # logpz = log_normal_pdf(z, 0., 0.)\n",
        "    # logqz_x = log_normal_pdf(z, mean, logvar)\n",
        "    # return -tf.reduce_mean(logpx_z + logpz - logqz_x)\n",
        "    return mse(x, x_logit)\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def compute_apply_gradients(model, x, optimizer):\n",
        "    with tf.GradientTape() as tape:\n",
        "        loss = compute_loss(model, x)\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "    return loss\n",
        "\n",
        "\n",
        "def generate_and_save_images(model, epoch, test_input):\n",
        "    predictions = model.sample(test_input)\n",
        "    fig = plt.figure(figsize=(4, 4))\n",
        "\n",
        "    for i in range(predictions.shape[0]):\n",
        "        plt.subplot(4, 4, i + 1)\n",
        "        plt.imshow(predictions[0])\n",
        "        plt.show()\n",
        "        # plt.imshow(predictions[i, :, :, 0], cmap='gray')\n",
        "        plt.axis('off')\n",
        "\n",
        "    # tight_layout minimizes the overlap between 2 sub-plots\n",
        "    plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def valid_model(model, image_input):\n",
        "    t = image_input\n",
        "    z = tf.random.normal(\n",
        "        shape=[1, 512],\n",
        "        mean=125,\n",
        "        stddev=100.0)\n",
        "    predictions = model.sample(z)\n",
        "    plt.imshow(predictions[0])\n",
        "    plt.show()\n",
        "    print(predictions[0])\n",
        "\n",
        "\n",
        "def display_image(epoch_no):\n",
        "    return PIL.Image.open('image_at_epoch_{:04d}.png'.format(epoch_no))\n",
        "\n",
        "\n",
        "def preprocess_image(image):\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    image = tf.image.resize(image, [128, 128])\n",
        "    image /= 255.0  # normalize to [0,1] range\n",
        "\n",
        "    return image\n",
        "\n",
        "\n",
        "def load_and_preprocess_image(path):\n",
        "    image = tf.io.read_file(path)\n",
        "    return preprocess_image(image)\n",
        "\n",
        "\n",
        "def data_load(path):\n",
        "    data_root = pathlib.Path(path)\n",
        "    all_image_paths = list(data_root.glob('*/*'))\n",
        "    all_image_paths = [str(path) for path in all_image_paths]\n",
        "    random.shuffle(all_image_paths)\n",
        "\n",
        "    image_count = len(all_image_paths)\n",
        "\n",
        "    label_names = sorted(item.name for item in data_root.glob('*/') if item.is_dir())\n",
        "\n",
        "    label_to_index = dict((name, index) for index, name in enumerate(label_names))\n",
        "\n",
        "    all_image_labels = [label_to_index[pathlib.Path(path).parent.name]\n",
        "                        for path in all_image_paths]\n",
        "\n",
        "    path_ds = tf.data.Dataset.from_tensor_slices(all_image_paths)\n",
        "\n",
        "    image_ds = path_ds.map(load_and_preprocess_image, num_parallel_calls=tf.data.experimental.AUTOTUNE).batch(BATCH_SIZE)\n",
        "\n",
        "    label_ds = tf.data.Dataset.from_tensor_slices(tf.cast(all_image_labels, tf.int64))\n",
        "    return image_ds, label_ds, image_count\n",
        "\n",
        "\n",
        "def main():\n",
        "    data_root = pathlib.Path(path)\n",
        "    all_image_paths = list(data_root.glob('*/*'))\n",
        "    all_image_paths = [str(path) for path in all_image_paths]\n",
        "    random.shuffle(all_image_paths)\n",
        "\n",
        "    image_count = len(all_image_paths)\n",
        "\n",
        "    label_names = sorted(item.name for item in data_root.glob('*/') if item.is_dir())\n",
        "\n",
        "    label_to_index = dict((name, index) for index, name in enumerate(label_names))\n",
        "\n",
        "    all_image_labels = [label_to_index[pathlib.Path(path).parent.name]\n",
        "                        for path in all_image_paths]\n",
        "\n",
        "    path_ds = tf.data.Dataset.from_tensor_slices(all_image_paths)\n",
        "\n",
        "    image_ds = path_ds.map(load_and_preprocess_image, num_parallel_calls=tf.data.experimental.AUTOTUNE).batch(BATCH_SIZE)\n",
        "\n",
        "    label_ds = tf.data.Dataset.from_tensor_slices(tf.cast(all_image_labels, tf.int64)).batch(BATCH_SIZE)\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "\n",
        "    epochs = 160\n",
        "    latent_dim = 512\n",
        "\n",
        "    model = CVAE(latent_dim)\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        i = 1\n",
        "        s = 0\n",
        "        start_time = time.time()\n",
        "        for train_x in image_ds:\n",
        "            loss = compute_apply_gradients(model, train_x, optimizer)\n",
        "            i = i + 1\n",
        "            s = s + loss\n",
        "        end_time = time.time()\n",
        "\n",
        "        if epoch % 1 == 0:\n",
        "            print('Epoch:{}, time elapse: {}, epoch_mse: {}'.format(epoch, end_time - start_time, s /(image_count/BATCH_SIZE)))\n",
        "            \n",
        "        if epoch % 20 == 0:\n",
        "            model.save_weights('/content/drive/My Drive/Autoencodercheckpoint/ckpt')\n",
        "\n",
        "\n",
        "\n",
        "def evaluate_my_model():\n",
        "    image_ds, label_ds, image_count = data_load(path)\n",
        "    mse = tf.keras.losses.MeanSquaredError()\n",
        "    new_model = CVAE(512)\n",
        "    new_model.load_weights('/content/drive/My Drive/Autoencodercheckpoint/ckpt')\n",
        "    noise = tf.random.normal(\n",
        "        shape=[1, 2048])\n",
        "    img = new_model.decode(noise)\n",
        "    j = 0\n",
        "    for image in image_ds:\n",
        "        z = new_model.encode(image)\n",
        "        y = new_model.sample(z)\n",
        "        i = 0\n",
        "        while i < BATCH_SIZE-1:\n",
        "            plt.imshow(y[i])\n",
        "            plt.grid(False)\n",
        "            plt.show()\n",
        "            i = i + 1\n",
        "            MSE = mse(y[i], image[i])\n",
        "            PSNR = 10 * math.log(1/MSE, 10)\n",
        "            print('MSE is: {}, PSNR is: {} dB'.format(MSE, PSNR))\n",
        "        j = j + 1\n",
        "        if j == 1:\n",
        "            return 0\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    train = True\n",
        "    if train:\n",
        "        main()\n",
        "    else:\n",
        "        evaluate_my_model()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:1, time elapse: 17.909494638442993, epoch_mse: 0.14872516691684723\n",
            "Epoch:2, time elapse: 13.293628454208374, epoch_mse: 0.06194490194320679\n",
            "Epoch:3, time elapse: 13.581155061721802, epoch_mse: 0.04840867966413498\n",
            "Epoch:4, time elapse: 13.721139192581177, epoch_mse: 0.03948279097676277\n",
            "Epoch:5, time elapse: 13.983022451400757, epoch_mse: 0.03463660180568695\n",
            "Epoch:6, time elapse: 14.311496019363403, epoch_mse: 0.031099652871489525\n",
            "Epoch:7, time elapse: 14.505247831344604, epoch_mse: 0.028854195028543472\n",
            "Epoch:8, time elapse: 14.42521595954895, epoch_mse: 0.027148503810167313\n",
            "Epoch:9, time elapse: 14.291471481323242, epoch_mse: 0.025706157088279724\n",
            "Epoch:10, time elapse: 14.212620735168457, epoch_mse: 0.024545900523662567\n",
            "Epoch:11, time elapse: 14.232304811477661, epoch_mse: 0.023588430136442184\n",
            "Epoch:12, time elapse: 14.307193994522095, epoch_mse: 0.023104486986994743\n",
            "Epoch:13, time elapse: 14.379414796829224, epoch_mse: 0.022164348512887955\n",
            "Epoch:14, time elapse: 14.404760837554932, epoch_mse: 0.02145060896873474\n",
            "Epoch:15, time elapse: 14.410316705703735, epoch_mse: 0.020714465528726578\n",
            "Epoch:16, time elapse: 14.372474431991577, epoch_mse: 0.020158428698778152\n",
            "Epoch:17, time elapse: 14.368907451629639, epoch_mse: 0.01980375498533249\n",
            "Epoch:18, time elapse: 14.36829137802124, epoch_mse: 0.019741002470254898\n",
            "Epoch:19, time elapse: 14.353881120681763, epoch_mse: 0.01955968700349331\n",
            "Epoch:20, time elapse: 14.354809761047363, epoch_mse: 0.01886446587741375\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}