{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "myautoencoder.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JiaSunDeepLearning/AutoEncoder/blob/master/myautoencoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kH4xmuGLJgG",
        "colab_type": "text"
      },
      "source": [
        "挂载GOOGLE云端硬盘"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDmaJgrnK_m2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "8f30d183-fca3-45c1-b909-1a2ccc9de5d7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQe7cAXQMC3Z",
        "colab_type": "text"
      },
      "source": [
        "尝试在GOOGLE云端硬盘中写入文件并读取"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynzkNSmjMCUG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d409d48f-9165-47dd-a6d4-ee3675de2857"
      },
      "source": [
        "with open('/content/drive/My Drive/Autoencodercheckpoint/foo.txt', 'w') as f:\n",
        "  f.write('Hello Google Drive!')\n",
        "!cat /content/drive/My\\ Drive/Autoencodercheckpoint/foo.txt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hello Google Drive!"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JTYSJMiIOnd",
        "colab_type": "text"
      },
      "source": [
        "选择2.x版本的tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjBjjp6SoqbE",
        "colab_type": "code",
        "outputId": "01092254-088c-4e6b-fd2a-ec64f0847aa9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hUBUiJ9IYGi",
        "colab_type": "text"
      },
      "source": [
        "导入需要的库"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dv7sloZBoyUR",
        "colab_type": "code",
        "outputId": "bd75d3ad-fbe5-4c52-ee10-572e5e70457e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "# TensorFlow and tf.keras\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# Helper libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(tf.__version__)\n",
        "import os\n",
        "import time\n",
        "import glob\n",
        "import imageio\n",
        "from IPython import display\n",
        "import pathlib\n",
        "import random\n",
        "import logging\n",
        "logger = tf.get_logger()\n",
        "logger.setLevel(logging.ERROR)\n",
        "import PIL\n",
        "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0-beta1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxSF4Vx-I5Lz",
        "colab_type": "text"
      },
      "source": [
        "下载本次训练使用的数据集"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1OyXyduo6qt",
        "colab_type": "code",
        "outputId": "519b18cd-490a-4908-93bb-f07a53b8d6e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
        "zip_dir = tf.keras.utils.get_file('cats_and_dogs_filterted.zip', origin=_URL, extract=True)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
            "68608000/68606236 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzB3ARu-JB4G",
        "colab_type": "text"
      },
      "source": [
        "读取训练集"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFMDx6Q8pMvB",
        "colab_type": "code",
        "outputId": "e7643e66-cb5d-48c7-c3f1-54df3eaaa094",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "\n",
        "zip_dir_base = os.path.dirname(zip_dir)\n",
        "!find $zip_dir_base -type d -print\n",
        "print(zip_dir_base)\n",
        "\n",
        "base_dir = os.path.join(os.path.dirname(zip_dir), 'cats_and_dogs_filtered')\n",
        "path = os.path.join(base_dir, 'train/')\n",
        "print(path)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root/.keras/datasets\n",
            "/root/.keras/datasets/cats_and_dogs_filtered\n",
            "/root/.keras/datasets/cats_and_dogs_filtered/train\n",
            "/root/.keras/datasets/cats_and_dogs_filtered/train/cats\n",
            "/root/.keras/datasets/cats_and_dogs_filtered/train/dogs\n",
            "/root/.keras/datasets/cats_and_dogs_filtered/validation\n",
            "/root/.keras/datasets/cats_and_dogs_filtered/validation/cats\n",
            "/root/.keras/datasets/cats_and_dogs_filtered/validation/dogs\n",
            "/root/.keras/datasets\n",
            "/root/.keras/datasets/cats_and_dogs_filtered/train/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGWOkIRHJO1Z",
        "colab_type": "text"
      },
      "source": [
        "开始训练"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5kOJV8yqsYN",
        "colab_type": "code",
        "outputId": "fc0f870a-f9c4-4ae6-9e9a-6a06c7ed04e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "BATCH_SIZE = 50\n",
        "# IMG_SHAPE = 256\n",
        "\n",
        "\n",
        "class CVAE(tf.keras.Model):\n",
        "    def __init__(self, latent_dim):\n",
        "        super(CVAE, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.inference_net = tf.keras.Sequential(\n",
        "            [\n",
        "                # tf.keras.layers.InputLayer(input_shape=(128, 128, 2)),\n",
        "                tf.keras.layers.Conv2D(\n",
        "                    filters=64, kernel_size=(5, 5), strides=(2, 2), activation='relu', data_format='channels_last',\n",
        "                    padding='valid'),\n",
        "                tf.keras.layers.BatchNormalization(),\n",
        "                tf.keras.layers.Conv2D(\n",
        "                    filters=128, kernel_size=(5, 5), strides=(2, 2), activation='relu', padding='valid'),\n",
        "                tf.keras.layers.BatchNormalization(),\n",
        "                tf.keras.layers.Conv2D(\n",
        "                    filters=256, kernel_size=(5, 5), strides=(2, 2), activation='relu', padding='valid'),\n",
        "                tf.keras.layers.BatchNormalization(),\n",
        "                tf.keras.layers.Conv2D(\n",
        "                    filters=512, kernel_size=(5, 5), strides=(2, 2), activation='relu', padding='valid'),\n",
        "                tf.keras.layers.BatchNormalization(),\n",
        "                tf.keras.layers.Flatten(),\n",
        "                # No activation\n",
        "                tf.keras.layers.Dropout(rate=0.3),\n",
        "                tf.keras.layers.Dense(1024, activation='relu'),\n",
        "\n",
        "                tf.keras.layers.Flatten(),\n",
        "                # No activation\n",
        "                tf.keras.layers.Dropout(rate=0.3),\n",
        "                tf.keras.layers.Dense(2048, activation='relu'),\n",
        "\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        self.generative_net = tf.keras.Sequential(\n",
        "            [\n",
        "                tf.keras.layers.InputLayer(input_shape=(2048,)),\n",
        "                tf.keras.layers.Dropout(rate=0.3),\n",
        "                tf.keras.layers.Dense(units=16 * 16 * 512, activation=tf.nn.relu),\n",
        "                tf.keras.layers.Reshape(target_shape=(16, 16, 512)),\n",
        "                tf.keras.layers.Conv2DTranspose(\n",
        "                    filters=256,\n",
        "                    kernel_size=(5, 5),\n",
        "                    strides=(2, 2),\n",
        "                    padding=\"SAME\",\n",
        "                    activation='relu'),\n",
        "                tf.keras.layers.BatchNormalization(),\n",
        "                tf.keras.layers.Conv2DTranspose(\n",
        "                    filters=128,\n",
        "                    kernel_size=(5, 5),\n",
        "                    strides=(2, 2),\n",
        "                    padding=\"SAME\",\n",
        "                    activation='relu'),\n",
        "                tf.keras.layers.BatchNormalization(),\n",
        "                tf.keras.layers.Conv2DTranspose(\n",
        "                    filters=32,\n",
        "                    kernel_size=(5, 5),\n",
        "                    strides=(2, 2),\n",
        "                    padding=\"SAME\",\n",
        "                    activation='relu'),\n",
        "                tf.keras.layers.BatchNormalization(),\n",
        "                # No activation\n",
        "                tf.keras.layers.Conv2DTranspose(\n",
        "                    filters=3, kernel_size=(5, 5), strides=(1, 1), padding=\"SAME\", activation='relu'),\n",
        "            ]\n",
        "        )\n",
        "\n",
        "    @tf.function\n",
        "    def sample(self, eps=None):\n",
        "        if eps is None:\n",
        "            eps = tf.random.normal(shape=(100, self.latent_dim))\n",
        "        return self.decode(eps, apply_sigmoid=True)\n",
        "\n",
        "    def encode(self, x):\n",
        "        # mean, logvar = tf.split(self.inference_net(x), num_or_size_splits=2, axis=1)\n",
        "        y = self.inference_net(x)\n",
        "        return y\n",
        "\n",
        "    def reparameterize(self, mean, logvar):\n",
        "        eps = tf.random.normal(shape=mean.shape)\n",
        "        return eps * tf.exp(logvar * .5) + mean\n",
        "\n",
        "    def decode(self, z, apply_sigmoid=False):\n",
        "        logits = self.generative_net(z)\n",
        "        if apply_sigmoid:\n",
        "            probs = tf.sigmoid(logits)\n",
        "            return probs\n",
        "\n",
        "        return logits\n",
        "\n",
        "    def sample_forward(self, x):\n",
        "        y = self.inference_net(x)\n",
        "        return y\n",
        "\n",
        "\n",
        "def log_normal_pdf(sample, mean, logvar, raxis=1):\n",
        "    log2pi = tf.math.log(2. * np.pi)\n",
        "    return tf.reduce_sum(\n",
        "        -.5 * ((sample - mean) ** 2. * tf.exp(-logvar) + logvar + log2pi),\n",
        "        axis=raxis)\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def compute_loss(model, x):\n",
        "    z = model.encode(x)\n",
        "    # z = model.reparameterize(mean, logvar)\n",
        "    x_logit = model.decode(z)\n",
        "    mse = tf.keras.losses.MeanSquaredError()\n",
        "\n",
        "    # cross_ent = tf.nn.l2_loss(x_logit-x)\n",
        "    # cross_ent = tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=x)\n",
        "    # logpx_z = -tf.reduce_sum(cross_ent, axis=[1, 2, 3])\n",
        "    # logpx_z = -tf.reduce_sum(cross_ent)\n",
        "    # logpz = log_normal_pdf(z, 0., 0.)\n",
        "    # logqz_x = log_normal_pdf(z, mean, logvar)\n",
        "    # return -tf.reduce_mean(logpx_z + logpz - logqz_x)\n",
        "    return mse(x, x_logit)\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def compute_apply_gradients(model, x, optimizer):\n",
        "    with tf.GradientTape() as tape:\n",
        "        loss = compute_loss(model, x)\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "    return loss\n",
        "\n",
        "\n",
        "def generate_and_save_images(model, epoch, test_input):\n",
        "    predictions = model.sample(test_input)\n",
        "    fig = plt.figure(figsize=(4, 4))\n",
        "\n",
        "    for i in range(predictions.shape[0]):\n",
        "        plt.subplot(4, 4, i + 1)\n",
        "        plt.imshow(predictions[0])\n",
        "        plt.show()\n",
        "        # plt.imshow(predictions[i, :, :, 0], cmap='gray')\n",
        "        plt.axis('off')\n",
        "\n",
        "    # tight_layout minimizes the overlap between 2 sub-plots\n",
        "    plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def valid_model(model, image_input):\n",
        "    t = image_input\n",
        "    z = tf.random.normal(\n",
        "        shape=[1, 512],\n",
        "        mean=125,\n",
        "        stddev=100.0)\n",
        "    predictions = model.sample(z)\n",
        "    plt.imshow(predictions[0])\n",
        "    plt.show()\n",
        "    print(predictions[0])\n",
        "\n",
        "\n",
        "def display_image(epoch_no):\n",
        "    return PIL.Image.open('image_at_epoch_{:04d}.png'.format(epoch_no))\n",
        "\n",
        "\n",
        "def preprocess_image(image):\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    image = tf.image.resize(image, [128, 128])\n",
        "    image /= 255.0  # normalize to [0,1] range\n",
        "\n",
        "    return image\n",
        "\n",
        "\n",
        "def load_and_preprocess_image(path):\n",
        "    image = tf.io.read_file(path)\n",
        "    return preprocess_image(image)\n",
        "\n",
        "\n",
        "def data_load(path):\n",
        "    data_root = pathlib.Path(path)\n",
        "    all_image_paths = list(data_root.glob('*/*'))\n",
        "    all_image_paths = [str(path) for path in all_image_paths]\n",
        "    random.shuffle(all_image_paths)\n",
        "\n",
        "    image_count = len(all_image_paths)\n",
        "\n",
        "    label_names = sorted(item.name for item in data_root.glob('*/') if item.is_dir())\n",
        "\n",
        "    label_to_index = dict((name, index) for index, name in enumerate(label_names))\n",
        "\n",
        "    all_image_labels = [label_to_index[pathlib.Path(path).parent.name]\n",
        "                        for path in all_image_paths]\n",
        "\n",
        "    path_ds = tf.data.Dataset.from_tensor_slices(all_image_paths)\n",
        "\n",
        "    image_ds = path_ds.map(load_and_preprocess_image, num_parallel_calls=tf.data.experimental.AUTOTUNE).batch(BATCH_SIZE)\n",
        "\n",
        "    label_ds = tf.data.Dataset.from_tensor_slices(tf.cast(all_image_labels, tf.int64))\n",
        "    return image_ds, label_ds, image_count\n",
        "\n",
        "\n",
        "def main():\n",
        "    # path = './cats_and_dogs_filtered/train/'\n",
        "    data_root = pathlib.Path(path)\n",
        "    all_image_paths = list(data_root.glob('*/*'))\n",
        "    all_image_paths = [str(path) for path in all_image_paths]\n",
        "    random.shuffle(all_image_paths)\n",
        "\n",
        "    image_count = len(all_image_paths)\n",
        "\n",
        "    label_names = sorted(item.name for item in data_root.glob('*/') if item.is_dir())\n",
        "\n",
        "    label_to_index = dict((name, index) for index, name in enumerate(label_names))\n",
        "\n",
        "    all_image_labels = [label_to_index[pathlib.Path(path).parent.name]\n",
        "                        for path in all_image_paths]\n",
        "\n",
        "    path_ds = tf.data.Dataset.from_tensor_slices(all_image_paths)\n",
        "\n",
        "    image_ds = path_ds.map(load_and_preprocess_image, num_parallel_calls=tf.data.experimental.AUTOTUNE).batch(BATCH_SIZE)\n",
        "\n",
        "    label_ds = tf.data.Dataset.from_tensor_slices(tf.cast(all_image_labels, tf.int64))\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "\n",
        "    epochs = 160\n",
        "    latent_dim = 512\n",
        "\n",
        "    # evaluate_my_model()\n",
        "\n",
        "    model = CVAE(latent_dim)\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        i = 1\n",
        "        s = 0\n",
        "        start_time = time.time()\n",
        "        for train_x in image_ds:\n",
        "            '''\n",
        "            while i < 1:\n",
        "                plt.imshow(train_x[i])\n",
        "                plt.grid(False)\n",
        "                plt.show()\n",
        "                i = i + 1\n",
        "            valid_model(model, train_x)\n",
        "            '''\n",
        "            loss = compute_apply_gradients(model, train_x, optimizer)\n",
        "            #print('Time: {}/{}, Epoch: {}, Batch_mse: {}'.format(i, image_count/BATCH_SIZE, epoch, loss))\n",
        "            i = i + 1\n",
        "            s = s + loss\n",
        "        end_time = time.time()\n",
        "\n",
        "        if epoch % 1 == 0:\n",
        "            '''\n",
        "            loss = tf.keras.metrics.Mean()\n",
        "            # for test_x in val_dataset:\n",
        "            #     loss(compute_loss(model, test_x))\n",
        "            elbo = -loss.result()\n",
        "            display.clear_output(wait=False)\n",
        "            print('Epoch: {}, Test set ELBO: {}, '\n",
        "                  'time elapse for current epoch {}'.format(epoch,\n",
        "                                                            elbo,\n",
        "                                                            end_time - start_time))\n",
        "            '''\n",
        "            print('Epoch:{}, time elapse: {}, epoch_mse: {}'.format(epoch, end_time - start_time, s / i))\n",
        "            \n",
        "        if epoch % 20 == 0:\n",
        "            model.save_weights('/content/drive/My Drive/Autoencodercheckpoint/ckpt')\n",
        "            for train_x in image_ds:\n",
        "                z = model.encode(image)\n",
        "                y = model.sample(z)\n",
        "                i = 0\n",
        "                while i < BATCH_SIZE:\n",
        "                    plt.imshow(y[i])\n",
        "                    plt.grid(False)\n",
        "                    plt.show()\n",
        "                    i = i + 1\n",
        "                \n",
        "    \n",
        "    \n",
        "    new_model = CVAE(512)\n",
        "    new_model.load_weights('/content/drive/My Drive/Autoencodercheckpoint/ckpt')\n",
        "    '''\n",
        "    print('evaluating')\n",
        "    for image in image_ds:\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            z = new_model.encode(image)\n",
        "            print(z)\n",
        "            y = new_model.sample(z)\n",
        "            while i < 6:\n",
        "                plt.imshow(y[i])\n",
        "                plt.grid(False)\n",
        "                plt.show()\n",
        "                i = i + 1\n",
        "            break\n",
        "    '''\n",
        "\n",
        "\n",
        "def evaluate_my_model():\n",
        "    path = './cats_and_dogs_filtered/train/'\n",
        "    optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "    image_ds, label_ds, image_count = data_load(path)\n",
        "\n",
        "    new_model = CVAE(512)\n",
        "    new_model.load_weights('/content/drive/My Drive/Autoencodercheckpoint/ckpt')\n",
        "    i = 0\n",
        "    noise = tf.random.normal(\n",
        "        shape=[1, 1024])\n",
        "    img = new_model.decode(noise)\n",
        "    # plt.imshow(img[0]*255)\n",
        "    # plt.show()\n",
        "\n",
        "    for image in image_ds:\n",
        "        z = new_model.encode(image)\n",
        "        print(tf.reduce_max(z), tf.reduce_min(z))\n",
        "        y = new_model.sample(z)\n",
        "        print(tf.reduce_max(y), tf.reduce_min(y))\n",
        "        while i < 5:\n",
        "            plt.imshow(y[i]*255)\n",
        "            plt.grid(False)\n",
        "            plt.show()\n",
        "            i = i + 1\n",
        "            break\n",
        "    return 0\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    train = True\n",
        "    if train:\n",
        "        main()\n",
        "    else:\n",
        "        evaluate_my_model()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:1, time elapse: 21.799038887023926, epoch_mse: 0.11327946931123734\n",
            "Epoch:2, time elapse: 12.627155303955078, epoch_mse: 0.04719863459467888\n",
            "Epoch:3, time elapse: 12.770352602005005, epoch_mse: 0.037310440093278885\n",
            "Epoch:4, time elapse: 12.853256464004517, epoch_mse: 0.03208382800221443\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}